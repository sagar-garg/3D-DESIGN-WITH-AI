{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance is dependent on choice of model and effective prompt generation.\n",
    "# Open-Source Models are found from Huggingface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONFIG\n",
    "DEFAULT_MODEL=\"google/flan-t5-small\"\n",
    "MODEL1=\"google/flan-t5-small\"\n",
    "MODEL2=\"google/flan-t5-large\"\n",
    "\n",
    "#Open Source Examples\n",
    "#flan-t5-small, flan-t5-base, flan-t5-large, flan-t5-xl, flan-t5-xxl\n",
    "#llama-2-7b, llama-2-13b, llama-2-70b\n",
    "#bloom-560m, bloom-1b1, bloom-7b1, bloomz-7b1-mt\n",
    "\n",
    "#Closed Source Examples\n",
    "#GPT-4\n",
    "\n",
    "\n",
    "PROMPT=\"I need a bracket that can support 20kg with two mounting holes.\"\n",
    "\n",
    "\n",
    "DEFAULT_PROMPT_TEMPLATE=(\"Extract design parameters as a Python dictionary with string keys and values.\\n\\n\"\n",
    "\"User's input:\\n\"\n",
    "\"{user_input}\\n\\n\")\n",
    "\n",
    "PROMPT_TEMPLATE1=(\"You are an AI assistant that extracts design parameters from text.\\n\\n\"\n",
    "    \"Instructions: The user will describe a design they need, mentioning various requirements. \"\n",
    "    \"Please read the user's text and identify any key design parameters, requirements, or features. \"\n",
    "    \"Extract key design parameters from the following input and return them as a valid Python dictionary with string keys and string or numeric values only. \"\n",
    "    \"Do not include any explanation, just the dictionary. \"\n",
    "    \"If some parameters are given in natural language, just return them as strings. \"\n",
    "    \"If quantitative values are mentioned, return them as strings with units. \"\n",
    "    \"Be as general as possible; do not assume categories in advance.\\n\\n\"\n",
    "    \"User's input:\\n\"\n",
    "    \"{user_input}\\n\\n\"\n",
    "    \"Output:\")\n",
    "\n",
    "PROMPT_TEMPLATE2 = (\n",
    "    \"You are an AI assistant that extracts design parameters from text.\\n\\n\"\n",
    "    \"Instructions: The user will describe a design they need, mentioning various requirements.\\n\\n\"\n",
    "    \"Please read the user's text and identify any key design parameters, requirements, or features.\\n\\n\"\n",
    "    \"Extract key design parameters from the following input and return them as a valid Python dictionary with string keys and string or numeric values only.\\n\\n\"\n",
    "    \"Do not include any explanation, just the dictionary.\\n\\n\"\n",
    "    \"If some parameters are given in natural language, just return them as strings.\\n\\n\"\n",
    "    \"If quantitative values are mentioned, return them as strings with units.\\n\\n\"\n",
    "    \"Be as general as possible; do not assume categories in advance.\\n\\n\"\n",
    "    \"Follow the examples below:\\n\\n\"\n",
    "    \n",
    "    \"Example 1:\\n\"\n",
    "    \"Input: I want a shelf that can hold 15kg and has three levels.\\n\"\n",
    "    \"Output: {{'type': 'shelf', 'capacity': '15kg', 'levels': '3'}}\\n\\n\"\n",
    "    \n",
    "    \"Example 2:\\n\"\n",
    "    \"Input: A pipe clamp that supports 500N of force and includes a hinge.\\n\"\n",
    "    \"Output: {{'type': 'pipe clamp', 'capacity': '500N', 'features': 'includes a hinge'}}\\n\\n\"\n",
    "    \n",
    "    \"Example 3:\\n\"\n",
    "    \"Input: I need a frame to hold a 10kg painting with a gold finish.\\n\"\n",
    "    \"Output: {{'type': 'frame', 'capacity': '10kg', 'features': 'gold finish'}}\\n\\n\"\n",
    "    \n",
    "    \"Example 4:\\n\"\n",
    "    \"Input: I want a mount for a TV that weighs 30kg with adjustable tilt.\\n\"\n",
    "    \"Output: {{'type': 'TV mount', 'capacity': '30kg', 'features': 'adjustable tilt'}}\\n\\n\"\n",
    "    \n",
    "    \"Now, process the following input and extract the design parameters:\\n\\n\"\n",
    "    \"Input: {user_input}\\n\"\n",
    "    \"Output:\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9998660087585449}]\n"
     ]
    }
   ],
   "source": [
    "# testing transformers is working\n",
    "from transformers import pipeline\n",
    "pipe = pipeline(\"sentiment-analysis\")\n",
    "print(pipe(\"This is working perfectly!\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Source Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "# Load a suitable instruction-following model (replace with a model you have access to)\n",
    "# For example, using a LLaMA-2 or a Flan-T5 large model:\n",
    "# Note: This is a placeholder. You need an appropriate model & weights that support instruction-following.\n",
    "# In practice, you might load something like:\n",
    "# pipe = pipeline(\"text-generation\", model=\"google/flan-t5-xxl\", device_map=\"auto\")\n",
    "#\n",
    "# Or if using an OpenAI API (not shown here since it's a different library),\n",
    "# you'd call the openai.Completion.create with a prompt.\n",
    "#\n",
    "# For demonstration, let's assume `pipe` is a pipeline capable of following instructions.\n",
    "\n",
    "def extract_design_parameters(user_input: str, prompt_template: str = DEFAULT_PROMPT_TEMPLATE):\n",
    "    \"\"\"\n",
    "    Extracts design parameters from the user's input using a specified prompt template.\n",
    "\n",
    "    Args:\n",
    "        user_input (str): The user's input text describing the design requirements.\n",
    "        prompt_template (str): The template for the prompt, formatted with the user_input.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing both the raw response and the stripped response, along with parsed parameters if possible.\n",
    "    \"\"\"\n",
    "    # Format the prompt with the user's input\n",
    "    prompt = prompt_template.format(user_input=user_input)\n",
    "    \n",
    "    # Generate the response\n",
    "    response = pipe(prompt)[0]['generated_text']\n",
    "    stripped_response = response.strip()  # Remove any leading/trailing whitespace\n",
    "\n",
    "    # Initialize the result dictionary\n",
    "    result = {\n",
    "        \"raw_response\": response,\n",
    "        \"stripped_response\": stripped_response,\n",
    "        \"parsed_parameters\": None  # Default to None until parsing is attempted\n",
    "    }\n",
    "\n",
    "    # Try to parse the stripped response as a dictionary\n",
    "    try:\n",
    "        extracted_params = ast.literal_eval(stripped_response)\n",
    "        if isinstance(extracted_params, dict):\n",
    "            result[\"parsed_parameters\"] = extracted_params\n",
    "        else:\n",
    "            # If parsing doesn't result in a dict, store the stripped response\n",
    "            result[\"parsed_parameters\"] = {\"parameters\": stripped_response}\n",
    "    except:\n",
    "        # If parsing fails, store the stripped response as is\n",
    "        result[\"parsed_parameters\"] = {\"parameters\": stripped_response}\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"text2text-generation\", model=MODEL1, max_new_tokens=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VB\n",
      "VB\n",
      "{'parameters': 'VB'}\n"
     ]
    }
   ],
   "source": [
    "user_input = PROMPT\n",
    "extracted = extract_design_parameters(user_input, DEFAULT_PROMPT_TEMPLATE)\n",
    "print(extracted['raw_response'])\n",
    "print(extracted['stripped_response'])\n",
    "print(extracted['parsed_parameters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'1'\n",
      "'1'\n",
      "{'parameters': \"'1'\"}\n"
     ]
    }
   ],
   "source": [
    "user_input = PROMPT\n",
    "extracted = extract_design_parameters(user_input, PROMPT_TEMPLATE1)\n",
    "print(extracted['raw_response'])\n",
    "print(extracted['stripped_response'])\n",
    "print(extracted['parsed_parameters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'type': bracket, 'capacity': '20kg', 'capacity': '2', 'mounting': '2'\n",
      "'type': bracket, 'capacity': '20kg', 'capacity': '2', 'mounting': '2'\n",
      "{'parameters': \"'type': bracket, 'capacity': '20kg', 'capacity': '2', 'mounting': '2'\"}\n"
     ]
    }
   ],
   "source": [
    "user_input = PROMPT\n",
    "extracted = extract_design_parameters(user_input, PROMPT_TEMPLATE2)\n",
    "print(extracted['raw_response'])\n",
    "print(extracted['stripped_response'])\n",
    "print(extracted['parsed_parameters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance depends on model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"text2text-generation\", model=MODEL2, max_new_tokens=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'bracket', 'capacity', '20kg', 'two mounting holes'\n",
      "'bracket', 'capacity', '20kg', 'two mounting holes'\n",
      "{'parameters': \"'bracket', 'capacity', '20kg', 'two mounting holes'\"}\n"
     ]
    }
   ],
   "source": [
    "user_input = PROMPT\n",
    "extracted = extract_design_parameters(user_input, PROMPT_TEMPLATE2)\n",
    "print(extracted['raw_response'])\n",
    "print(extracted['stripped_response'])\n",
    "print(extracted['parsed_parameters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closed Source Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the below code in your terminal to protect your key.\n",
    "# export OPENAI_API_KEY=\"your-api-key\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key=api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def extract_design_parameters(user_input: str):\n",
    "    \"\"\"\n",
    "    Extracts design parameters from the user input using GPT-3.5 or GPT-4.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        \"You are an AI assistant that extracts design parameters from text.\\n\\n\"\n",
    "        \"Instructions: The user will describe a design they need, mentioning various requirements.\\n\\n\"\n",
    "        \"Extract the design parameters and return them as a Python dictionary with string keys and values only.\\n\\n\"\n",
    "        f\"Input: {user_input}\\n\\n\"\n",
    "        \"Output:\"\n",
    "    )\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",  # Or \"gpt-4\" for better quality\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    return response['choices'][0]['message']['content'].strip()\n",
    "\n",
    "# Example usage\n",
    "user_input = \"I need a bracket that can support 20kg with two mounting holes.\"\n",
    "print(extract_design_parameters(user_input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"I need a bracket that can support 20kg with two mounting holes.\"\n",
    "print(extract_design_parameters(user_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # I am pasting the response that I got from web api using GPT-4-o.\n",
    "# prompt=\"You are an AI assistant that extracts design parameters from text.\"\n",
    "#         \"Instructions: The user will describe a design they need, mentioning various requirements.\"\n",
    "#         \"Extract the design parameters and return them as a Python dictionary with string keys and values only.\"\n",
    "\n",
    "# user_input = \"I need a bracket that can support 20kg with two mounting holes.\"\n",
    "# output=\n",
    "# {\n",
    "#     \"type\": \"bracket\",\n",
    "#     \"load_capacity\": \"20kg\",\n",
    "#     \"mounting_holes\": \"2\"\n",
    "# }\n",
    "# #which is good.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers-tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
